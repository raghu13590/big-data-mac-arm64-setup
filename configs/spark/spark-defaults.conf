# Enable event logging and point to local directory for Spark History Server
spark.eventLog.enabled=true
spark.eventLog.dir=file:/opt/spark/history
spark.history.fs.logDirectory=file:/opt/spark/history

# Configure HDFS (when using with Hadoop)
spark.hadoop.fs.defaultFS=hdfs://namenode:9000

# Configure YARN for resource management
spark.hadoop.yarn.resourcemanager.address=resourcemanager:8032
spark.hadoop.yarn.resourcemanager.scheduler.address=resourcemanager:8030

# Set classpath for Hadoop/YARN integration
spark.hadoop.yarn.application.classpath=/opt/hadoop-3.3.6/etc/hadoop,/opt/hadoop-3.3.6/share/hadoop/common/*,/opt/hadoop-3.3.6/share/hadoop/common/lib/*,/opt/hadoop-3.3.6/share/hadoop/hdfs/*,/opt/hadoop-3.3.6/share/hadoop/hdfs/lib/*,/opt/hadoop-3.3.6/share/hadoop/yarn/*,/opt/hadoop-3.3.6/share/hadoop/yarn/lib/*,/opt/hadoop-3.3.6/share/hadoop/mapreduce/*,/opt/hadoop-3.3.6/share/hadoop/mapreduce/lib/*,/opt/hadoop-3.3.6/share/hadoop/tools/lib/*

# Configure Hive for Spark SQL integration
spark.sql.hive.metastore.jars=/opt/spark/jars/*
spark.sql.hive.metastore.uris=thrift://metastore:9083
spark.sql.warehouse.dir=hdfs://namenode:9000/user/hive/warehouse

# Set default parallelism for standalone mode
spark.default.parallelism=4

# Enable Snappy compression
spark.io.compression.codec=snappy

# Optional: Set the master to 'local' when running without Hadoop
# Uncomment the following line if you want Spark to run in standalone mode by default:
#spark.master=local[*]